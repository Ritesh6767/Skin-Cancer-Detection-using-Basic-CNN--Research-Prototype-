{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32800c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Dataset prepared: train/ and val/ folders with resized images\n",
      "Found 8012 images belonging to 2 classes.\n",
      "Found 2003 images belonging to 2 classes.\n",
      " Loaded 8012 training images and 2003 validation images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rites\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m285s\u001b[0m 1s/step - accuracy: 0.8049 - loss: 0.4720 - val_accuracy: 0.8048 - val_loss: 0.4283\n",
      "Epoch 2/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 503ms/step - accuracy: 0.8049 - loss: 0.4544 - val_accuracy: 0.8048 - val_loss: 0.4932\n",
      "Epoch 3/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 467ms/step - accuracy: 0.8049 - loss: 0.4269 - val_accuracy: 0.8048 - val_loss: 0.4070\n",
      "Epoch 4/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 449ms/step - accuracy: 0.8049 - loss: 0.4385 - val_accuracy: 0.8048 - val_loss: 0.4128\n",
      "Epoch 5/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 528ms/step - accuracy: 0.8045 - loss: 0.4093 - val_accuracy: 0.8058 - val_loss: 0.4016\n",
      "Epoch 6/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 498ms/step - accuracy: 0.8067 - loss: 0.3981 - val_accuracy: 0.8088 - val_loss: 0.3803\n",
      "Epoch 7/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 531ms/step - accuracy: 0.8085 - loss: 0.3893 - val_accuracy: 0.8123 - val_loss: 0.3825\n",
      "Epoch 8/10\n",
      "\u001b[1m251/251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 475ms/step - accuracy: 0.8138 - loss: 0.3810 - val_accuracy: 0.8233 - val_loss: 0.3625\n",
      "Epoch 9/10\n",
      "\u001b[1m162/251\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 457ms/step - accuracy: 0.8197 - loss: 0.3588"
     ]
    }
   ],
   "source": [
    "import os, shutil, random\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# 1. Kaggle Dataset Download\n",
    "\n",
    "\n",
    "# Use a raw string or forward slashes to avoid unicode escape issues on Windows\n",
    "base_dir = r\"C:\\Users\\rites\\Downloads\\Projects\\Skin-Cancer-Detection-using-Basic-CNN--Research-Prototype-\"\n",
    "images_dir = os.path.join(base_dir, \"images\")\n",
    "metadata_path = os.path.join(base_dir, \"GroundTruth.csv\")\n",
    "train_dir = os.path.join(base_dir, \"train\")\n",
    "val_dir   = os.path.join(base_dir, \"val\")\n",
    "\n",
    "\n",
    "# 2. Split + Resize helper\n",
    "\n",
    "for split in [\"train\", \"val\"]:\n",
    "    for cls in [\"benign\", \"malignant\"]:\n",
    "        os.makedirs(os.path.join(base_dir, split, cls), exist_ok=True)\n",
    "\n",
    "train_benign_path = os.path.join(train_dir, \"benign\")\n",
    "train_malignant_path = os.path.join(train_dir, \"malignant\")\n",
    "\n",
    "def has_images(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        return False\n",
    "    files = [f for f in os.listdir(directory) if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n",
    "    return len(files) > 0\n",
    "\n",
    "\n",
    "def prepare_dataset(split_ratio=0.8, size=(128, 128)):\n",
    "    if not os.path.exists(images_dir):\n",
    "        print(f\"⚠️  Images directory not found at {images_dir}\")\n",
    "        return False\n",
    "    if not os.path.exists(metadata_path):\n",
    "        print(f\"⚠️  GroundTruth.csv not found at {metadata_path}\")\n",
    "        return False\n",
    "\n",
    "    df = pd.read_csv(metadata_path)\n",
    "    df['filepath'] = df['image'].apply(lambda x: os.path.join(images_dir, f\"{x}.jpg\"))\n",
    "    df = df[df['filepath'].apply(os.path.exists)]\n",
    "    if df.empty:\n",
    "        print(\"⚠️  No matching images found between GroundTruth.csv and the images directory\")\n",
    "        return False\n",
    "\n",
    "    malignant_cols = [\"MEL\", \"BCC\", \"AKIEC\"]\n",
    "    df['label'] = np.where(df[malignant_cols].sum(axis=1) > 0, \"malignant\", \"benign\")\n",
    "\n",
    "    train_df, val_df = train_test_split(\n",
    "        df,\n",
    "        test_size=1 - split_ratio,\n",
    "        stratify=df['label'],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    for split_name, split_df in [(\"train\", train_df), (\"val\", val_df)]:\n",
    "        for _, row in split_df.iterrows():\n",
    "            dst_path = os.path.join(base_dir, split_name, row['label'], f\"{row['image']}.jpg\")\n",
    "            if os.path.exists(dst_path):\n",
    "                continue\n",
    "            try:\n",
    "                with Image.open(row['filepath']) as img:\n",
    "                    img = img.convert('RGB').resize(size)\n",
    "                    img.save(dst_path)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not process {row['filepath']}: {e}\")\n",
    "\n",
    "    print(\"✅ Dataset prepared: train/ and val/ folders with resized images\")\n",
    "    return True\n",
    "\n",
    "\n",
    "if has_images(train_benign_path) and has_images(train_malignant_path):\n",
    "    print(\"✅ Using existing train/val data structure\")\n",
    "else:\n",
    "    if not prepare_dataset():\n",
    "        raise ValueError(\"Dataset preparation failed. Please ensure images and GroundTruth.csv are available.\")\n",
    "\n",
    "# 3. Data Generators\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    train_dir, target_size=(128,128), batch_size=32, class_mode='binary')\n",
    "\n",
    "val_gen = val_datagen.flow_from_directory(\n",
    "    val_dir, target_size=(128,128), batch_size=32, class_mode='binary')\n",
    "\n",
    "# Check if data was loaded successfully\n",
    "if train_gen.samples == 0 or val_gen.samples == 0:\n",
    "    raise ValueError(\"No images found in train or validation directories. Please ensure data is properly loaded.\")\n",
    "    \n",
    "print(f\" Loaded {train_gen.samples} training images and {val_gen.samples} validation images\")\n",
    "\n",
    "\n",
    "# 4. CNN Model\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3,3), activation='relu', input_shape=(128,128,3)),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# 5. Training\n",
    "\n",
    "history = model.fit(train_gen, epochs=10, validation_data=val_gen)\n",
    "\n",
    "\n",
    "# 6. Evaluation\n",
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for images, labels in val_gen:\n",
    "    preds = model(images, training=False)\n",
    "    y_true.extend(labels)\n",
    "    y_pred.extend((preds > 0.5).astype(int).flatten())\n",
    "    if len(y_true) >= val_gen.samples:\n",
    "        break\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.2f}\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(); plt.show()\n",
    "\n",
    "# 7. Grad-CAM Visualization (Optional - requires a test image)\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        loss = predictions[:, 0]\n",
    "    grads = tape.gradient(loss, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = np.maximum(heatmap, 0) / np.max(heatmap)\n",
    "    return heatmap\n",
    "\n",
    "# Try to find a sample image for Grad-CAM\n",
    "sample_paths = [\n",
    "    \"./data/sample.jpg\",\n",
    "    \"./data/sample.png\",\n",
    "    os.path.join(train_dir, \"benign\"),\n",
    "    os.path.join(train_dir, \"malignant\"),\n",
    "    os.path.join(val_dir, \"benign\"),\n",
    "    os.path.join(val_dir, \"malignant\")\n",
    "]\n",
    "\n",
    "img_path = None\n",
    "for path in sample_paths:\n",
    "    if os.path.isfile(path) and path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        img_path = path\n",
    "        break\n",
    "    elif os.path.isdir(path):\n",
    "        files = [f for f in os.listdir(path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        if len(files) > 0:\n",
    "            img_path = os.path.join(path, files[0])\n",
    "            break\n",
    "\n",
    "if img_path and os.path.exists(img_path):\n",
    "    try:\n",
    "        last_conv_layer_name = [layer.name for layer in model.layers if isinstance(layer, layers.Conv2D)][-1]\n",
    "        img = tf.keras.preprocessing.image.load_img(img_path, target_size=(128,128))\n",
    "        img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
    "        \n",
    "        heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
    "        plt.matshow(heatmap)\n",
    "        plt.title(\"Grad-CAM Heatmap\")\n",
    "        plt.show()\n",
    "        \n",
    "        img_cv = cv2.imread(img_path)\n",
    "        if img_cv is not None:\n",
    "            heatmap_resized = cv2.resize(heatmap.numpy(), (img_cv.shape[1], img_cv.shape[0]))\n",
    "            heatmap_resized = np.uint8(255 * heatmap_resized)\n",
    "            heatmap_colored = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
    "            superimposed_img = cv2.addWeighted(img_cv, 0.6, heatmap_colored, 0.4, 0)\n",
    "            cv2.imshow(\"Grad-CAM\", superimposed_img)\n",
    "            cv2.waitKey(0)\n",
    "            cv2.destroyAllWindows()\n",
    "    except Exception as e:\n",
    "        print(f\" Grad-CAM visualization skipped: {e}\")\n",
    "else:\n",
    "    print(\"Grad-CAM visualization skipped: No sample image found\")\n",
    "\n",
    "# 8. Save Model\n",
    "\n",
    "model.save(\"skin_cancer_cnn.h5\")\n",
    "print(\" Model saved as skin_cancer_cnn.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
